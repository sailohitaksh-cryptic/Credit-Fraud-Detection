{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing the Data into our Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('Creditcard_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>-0.371407</td>\n",
       "      <td>1.341262</td>\n",
       "      <td>0.359894</td>\n",
       "      <td>-0.358091</td>\n",
       "      <td>-0.137134</td>\n",
       "      <td>0.517617</td>\n",
       "      <td>0.401726</td>\n",
       "      <td>-0.058133</td>\n",
       "      <td>0.068653</td>\n",
       "      <td>-0.033194</td>\n",
       "      <td>0.084968</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>-0.099254</td>\n",
       "      <td>-1.416907</td>\n",
       "      <td>-0.153826</td>\n",
       "      <td>-0.751063</td>\n",
       "      <td>0.167372</td>\n",
       "      <td>0.050144</td>\n",
       "      <td>-0.443587</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>-0.611987</td>\n",
       "      <td>-0.045575</td>\n",
       "      <td>-0.219633</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.644269</td>\n",
       "      <td>1.417964</td>\n",
       "      <td>1.074380</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.428118</td>\n",
       "      <td>1.120631</td>\n",
       "      <td>-3.807864</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>1.249376</td>\n",
       "      <td>-0.619468</td>\n",
       "      <td>0.291474</td>\n",
       "      <td>1.757964</td>\n",
       "      <td>-1.323865</td>\n",
       "      <td>0.686133</td>\n",
       "      <td>-0.076127</td>\n",
       "      <td>-1.222127</td>\n",
       "      <td>-0.358222</td>\n",
       "      <td>0.324505</td>\n",
       "      <td>-0.156742</td>\n",
       "      <td>1.943465</td>\n",
       "      <td>-1.015455</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.649709</td>\n",
       "      <td>-0.415267</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-1.206921</td>\n",
       "      <td>-1.085339</td>\n",
       "      <td>40.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.894286</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>-0.113192</td>\n",
       "      <td>-0.271526</td>\n",
       "      <td>2.669599</td>\n",
       "      <td>3.721818</td>\n",
       "      <td>0.370145</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>-0.410430</td>\n",
       "      <td>-0.705117</td>\n",
       "      <td>-0.110452</td>\n",
       "      <td>-0.286254</td>\n",
       "      <td>0.074355</td>\n",
       "      <td>-0.328783</td>\n",
       "      <td>-0.210077</td>\n",
       "      <td>-0.499768</td>\n",
       "      <td>0.118765</td>\n",
       "      <td>0.570328</td>\n",
       "      <td>0.052736</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.268092</td>\n",
       "      <td>-0.204233</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>93.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>-0.366846</td>\n",
       "      <td>1.017614</td>\n",
       "      <td>0.836390</td>\n",
       "      <td>1.006844</td>\n",
       "      <td>-0.443523</td>\n",
       "      <td>0.150219</td>\n",
       "      <td>0.739453</td>\n",
       "      <td>-0.540980</td>\n",
       "      <td>0.476677</td>\n",
       "      <td>0.451773</td>\n",
       "      <td>0.203711</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "5     2 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
       "6     4  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n",
       "7     7 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
       "8     7 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
       "9     9 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "5  0.260314 -0.568671 -0.371407  1.341262  0.359894 -0.358091 -0.137134   \n",
       "6  0.081213  0.464960 -0.099254 -1.416907 -0.153826 -0.751063  0.167372   \n",
       "7 -3.807864  0.615375  1.249376 -0.619468  0.291474  1.757964 -1.323865   \n",
       "8  0.851084 -0.392048 -0.410430 -0.705117 -0.110452 -0.286254  0.074355   \n",
       "9  0.069539 -0.736727 -0.366846  1.017614  0.836390  1.006844 -0.443523   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "5  0.517617  0.401726 -0.058133  0.068653 -0.033194  0.084968 -0.208254   \n",
       "6  0.050144 -0.443587  0.002821 -0.611987 -0.045575 -0.219633 -0.167716   \n",
       "7  0.686133 -0.076127 -1.222127 -0.358222  0.324505 -0.156742  1.943465   \n",
       "8 -0.328783 -0.210077 -0.499768  0.118765  0.570328  0.052736 -0.073425   \n",
       "9  0.150219  0.739453 -0.540980  0.476677  0.451773  0.203711 -0.246914   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "5 -0.559825 -0.026398 -0.371427 -0.232794  0.105915  0.253844  0.081080   \n",
       "6 -0.270710 -0.154104 -0.780055  0.750137 -0.257237  0.034507  0.005168   \n",
       "7 -1.015455  0.057504 -0.649709 -0.415267 -0.051634 -1.206921 -1.085339   \n",
       "8 -0.268092 -0.204233  1.011592  0.373205 -0.384157  0.011747  0.142404   \n",
       "9 -0.633753 -0.120794 -0.385050 -0.069733  0.094199  0.246219  0.083076   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      1  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  \n",
       "5    3.67      0  \n",
       "6    4.99      0  \n",
       "7   40.80      0  \n",
       "8   93.20      0  \n",
       "9    3.68      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 772 entries, 0 to 771\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Time    772 non-null    int64  \n",
      " 1   V1      772 non-null    float64\n",
      " 2   V2      772 non-null    float64\n",
      " 3   V3      772 non-null    float64\n",
      " 4   V4      772 non-null    float64\n",
      " 5   V5      772 non-null    float64\n",
      " 6   V6      772 non-null    float64\n",
      " 7   V7      772 non-null    float64\n",
      " 8   V8      772 non-null    float64\n",
      " 9   V9      772 non-null    float64\n",
      " 10  V10     772 non-null    float64\n",
      " 11  V11     772 non-null    float64\n",
      " 12  V12     772 non-null    float64\n",
      " 13  V13     772 non-null    float64\n",
      " 14  V14     772 non-null    float64\n",
      " 15  V15     772 non-null    float64\n",
      " 16  V16     772 non-null    float64\n",
      " 17  V17     772 non-null    float64\n",
      " 18  V18     772 non-null    float64\n",
      " 19  V19     772 non-null    float64\n",
      " 20  V20     772 non-null    float64\n",
      " 21  V21     772 non-null    float64\n",
      " 22  V22     772 non-null    float64\n",
      " 23  V23     772 non-null    float64\n",
      " 24  V24     772 non-null    float64\n",
      " 25  V25     772 non-null    float64\n",
      " 26  V26     772 non-null    float64\n",
      " 27  V27     772 non-null    float64\n",
      " 28  V28     772 non-null    float64\n",
      " 29  Amount  772 non-null    float64\n",
      " 30  Class   772 non-null    int64  \n",
      "dtypes: float64(29), int64(2)\n",
      "memory usage: 187.1 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(772, 31)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "772"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Total_transactions = len(data)\n",
    "Total_transactions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Number of Normal transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "763"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal = len(data[data.Class == 0])\n",
    "normal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Number of Fraudulent Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraudulent = len(data[data.Class == 1])\n",
    "fraudulent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.18"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_percentage = round(fraudulent/normal*100, 2)\n",
    "fraud_percentage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we can see clearly the number of fraud cases is really low and if we apply undersampling it may lead to very inaccurate predictions. Therefore we will avoid it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(data.Amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3828.04"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(data.Amount)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First We will aplly the Machine Learning Models without Balancing the Model and see the outcome\n",
    "#### The Models we will be using are:-\n",
    "* Decision Tree Classifier\n",
    "* Random Forest Classifier\n",
    "* Logistic Regression\n",
    "* Extra Trees Classifier\n",
    "* K-Nearest Neighbour\n",
    "* SVM \n",
    "* XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.10'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pycaret\n",
    "pycaret.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "This version of PyCaret requires scikit-learn==0.23.2, got 1.0.2. Support for newer scikit-learn versions will be added in a future release.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpycaret\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mclassification\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m----> 2\u001b[0m clf1 \u001b[39m=\u001b[39m setup(data\u001b[39m=\u001b[39;49mdata, target\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mClass\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32me:\\anaconda\\lib\\site-packages\\pycaret\\classification.py:599\u001b[0m, in \u001b[0;36msetup\u001b[1;34m(data, target, train_size, test_data, preprocess, imputation_type, iterative_imputation_iters, categorical_features, categorical_imputation, categorical_iterative_imputer, ordinal_features, high_cardinality_features, high_cardinality_method, numeric_features, numeric_imputation, numeric_iterative_imputer, date_features, ignore_features, normalize, normalize_method, transformation, transformation_method, handle_unknown_categorical, unknown_categorical_method, pca, pca_method, pca_components, ignore_low_variance, combine_rare_levels, rare_level_threshold, bin_numeric_features, remove_outliers, outliers_threshold, remove_multicollinearity, multicollinearity_threshold, remove_perfect_collinearity, create_clusters, cluster_iter, polynomial_features, polynomial_degree, trigonometry_features, polynomial_threshold, group_features, group_names, feature_selection, feature_selection_threshold, feature_selection_method, feature_interaction, feature_ratio, interaction_threshold, fix_imbalance, fix_imbalance_method, data_split_shuffle, data_split_stratify, fold_strategy, fold, fold_shuffle, fold_groups, n_jobs, use_gpu, custom_pipeline, html, session_id, log_experiment, experiment_name, experiment_custom_tags, log_plots, log_profile, log_data, silent, verbose, profile, profile_kwargs)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[39mif\u001b[39;00m log_plots \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    597\u001b[0m     log_plots \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mauc\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mconfusion_matrix\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfeature\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m--> 599\u001b[0m \u001b[39mreturn\u001b[39;00m pycaret\u001b[39m.\u001b[39;49minternal\u001b[39m.\u001b[39;49mtabular\u001b[39m.\u001b[39;49msetup(\n\u001b[0;32m    600\u001b[0m     ml_usecase\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mclassification\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    601\u001b[0m     available_plots\u001b[39m=\u001b[39;49mavailable_plots,\n\u001b[0;32m    602\u001b[0m     data\u001b[39m=\u001b[39;49mdata,\n\u001b[0;32m    603\u001b[0m     target\u001b[39m=\u001b[39;49mtarget,\n\u001b[0;32m    604\u001b[0m     train_size\u001b[39m=\u001b[39;49mtrain_size,\n\u001b[0;32m    605\u001b[0m     test_data\u001b[39m=\u001b[39;49mtest_data,\n\u001b[0;32m    606\u001b[0m     preprocess\u001b[39m=\u001b[39;49mpreprocess,\n\u001b[0;32m    607\u001b[0m     imputation_type\u001b[39m=\u001b[39;49mimputation_type,\n\u001b[0;32m    608\u001b[0m     iterative_imputation_iters\u001b[39m=\u001b[39;49miterative_imputation_iters,\n\u001b[0;32m    609\u001b[0m     categorical_features\u001b[39m=\u001b[39;49mcategorical_features,\n\u001b[0;32m    610\u001b[0m     categorical_imputation\u001b[39m=\u001b[39;49mcategorical_imputation,\n\u001b[0;32m    611\u001b[0m     categorical_iterative_imputer\u001b[39m=\u001b[39;49mcategorical_iterative_imputer,\n\u001b[0;32m    612\u001b[0m     ordinal_features\u001b[39m=\u001b[39;49mordinal_features,\n\u001b[0;32m    613\u001b[0m     high_cardinality_features\u001b[39m=\u001b[39;49mhigh_cardinality_features,\n\u001b[0;32m    614\u001b[0m     high_cardinality_method\u001b[39m=\u001b[39;49mhigh_cardinality_method,\n\u001b[0;32m    615\u001b[0m     numeric_features\u001b[39m=\u001b[39;49mnumeric_features,\n\u001b[0;32m    616\u001b[0m     numeric_imputation\u001b[39m=\u001b[39;49mnumeric_imputation,\n\u001b[0;32m    617\u001b[0m     numeric_iterative_imputer\u001b[39m=\u001b[39;49mnumeric_iterative_imputer,\n\u001b[0;32m    618\u001b[0m     date_features\u001b[39m=\u001b[39;49mdate_features,\n\u001b[0;32m    619\u001b[0m     ignore_features\u001b[39m=\u001b[39;49mignore_features,\n\u001b[0;32m    620\u001b[0m     normalize\u001b[39m=\u001b[39;49mnormalize,\n\u001b[0;32m    621\u001b[0m     normalize_method\u001b[39m=\u001b[39;49mnormalize_method,\n\u001b[0;32m    622\u001b[0m     transformation\u001b[39m=\u001b[39;49mtransformation,\n\u001b[0;32m    623\u001b[0m     transformation_method\u001b[39m=\u001b[39;49mtransformation_method,\n\u001b[0;32m    624\u001b[0m     handle_unknown_categorical\u001b[39m=\u001b[39;49mhandle_unknown_categorical,\n\u001b[0;32m    625\u001b[0m     unknown_categorical_method\u001b[39m=\u001b[39;49munknown_categorical_method,\n\u001b[0;32m    626\u001b[0m     pca\u001b[39m=\u001b[39;49mpca,\n\u001b[0;32m    627\u001b[0m     pca_method\u001b[39m=\u001b[39;49mpca_method,\n\u001b[0;32m    628\u001b[0m     pca_components\u001b[39m=\u001b[39;49mpca_components,\n\u001b[0;32m    629\u001b[0m     ignore_low_variance\u001b[39m=\u001b[39;49mignore_low_variance,\n\u001b[0;32m    630\u001b[0m     combine_rare_levels\u001b[39m=\u001b[39;49mcombine_rare_levels,\n\u001b[0;32m    631\u001b[0m     rare_level_threshold\u001b[39m=\u001b[39;49mrare_level_threshold,\n\u001b[0;32m    632\u001b[0m     bin_numeric_features\u001b[39m=\u001b[39;49mbin_numeric_features,\n\u001b[0;32m    633\u001b[0m     remove_outliers\u001b[39m=\u001b[39;49mremove_outliers,\n\u001b[0;32m    634\u001b[0m     outliers_threshold\u001b[39m=\u001b[39;49moutliers_threshold,\n\u001b[0;32m    635\u001b[0m     remove_multicollinearity\u001b[39m=\u001b[39;49mremove_multicollinearity,\n\u001b[0;32m    636\u001b[0m     multicollinearity_threshold\u001b[39m=\u001b[39;49mmulticollinearity_threshold,\n\u001b[0;32m    637\u001b[0m     remove_perfect_collinearity\u001b[39m=\u001b[39;49mremove_perfect_collinearity,\n\u001b[0;32m    638\u001b[0m     create_clusters\u001b[39m=\u001b[39;49mcreate_clusters,\n\u001b[0;32m    639\u001b[0m     cluster_iter\u001b[39m=\u001b[39;49mcluster_iter,\n\u001b[0;32m    640\u001b[0m     polynomial_features\u001b[39m=\u001b[39;49mpolynomial_features,\n\u001b[0;32m    641\u001b[0m     polynomial_degree\u001b[39m=\u001b[39;49mpolynomial_degree,\n\u001b[0;32m    642\u001b[0m     trigonometry_features\u001b[39m=\u001b[39;49mtrigonometry_features,\n\u001b[0;32m    643\u001b[0m     polynomial_threshold\u001b[39m=\u001b[39;49mpolynomial_threshold,\n\u001b[0;32m    644\u001b[0m     group_features\u001b[39m=\u001b[39;49mgroup_features,\n\u001b[0;32m    645\u001b[0m     group_names\u001b[39m=\u001b[39;49mgroup_names,\n\u001b[0;32m    646\u001b[0m     feature_selection\u001b[39m=\u001b[39;49mfeature_selection,\n\u001b[0;32m    647\u001b[0m     feature_selection_threshold\u001b[39m=\u001b[39;49mfeature_selection_threshold,\n\u001b[0;32m    648\u001b[0m     feature_selection_method\u001b[39m=\u001b[39;49mfeature_selection_method,\n\u001b[0;32m    649\u001b[0m     feature_interaction\u001b[39m=\u001b[39;49mfeature_interaction,\n\u001b[0;32m    650\u001b[0m     feature_ratio\u001b[39m=\u001b[39;49mfeature_ratio,\n\u001b[0;32m    651\u001b[0m     interaction_threshold\u001b[39m=\u001b[39;49minteraction_threshold,\n\u001b[0;32m    652\u001b[0m     fix_imbalance\u001b[39m=\u001b[39;49mfix_imbalance,\n\u001b[0;32m    653\u001b[0m     fix_imbalance_method\u001b[39m=\u001b[39;49mfix_imbalance_method,\n\u001b[0;32m    654\u001b[0m     data_split_shuffle\u001b[39m=\u001b[39;49mdata_split_shuffle,\n\u001b[0;32m    655\u001b[0m     data_split_stratify\u001b[39m=\u001b[39;49mdata_split_stratify,\n\u001b[0;32m    656\u001b[0m     fold_strategy\u001b[39m=\u001b[39;49mfold_strategy,\n\u001b[0;32m    657\u001b[0m     fold\u001b[39m=\u001b[39;49mfold,\n\u001b[0;32m    658\u001b[0m     fold_shuffle\u001b[39m=\u001b[39;49mfold_shuffle,\n\u001b[0;32m    659\u001b[0m     fold_groups\u001b[39m=\u001b[39;49mfold_groups,\n\u001b[0;32m    660\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    661\u001b[0m     use_gpu\u001b[39m=\u001b[39;49muse_gpu,\n\u001b[0;32m    662\u001b[0m     custom_pipeline\u001b[39m=\u001b[39;49mcustom_pipeline,\n\u001b[0;32m    663\u001b[0m     html\u001b[39m=\u001b[39;49mhtml,\n\u001b[0;32m    664\u001b[0m     session_id\u001b[39m=\u001b[39;49msession_id,\n\u001b[0;32m    665\u001b[0m     log_experiment\u001b[39m=\u001b[39;49mlog_experiment,\n\u001b[0;32m    666\u001b[0m     experiment_name\u001b[39m=\u001b[39;49mexperiment_name,\n\u001b[0;32m    667\u001b[0m     experiment_custom_tags\u001b[39m=\u001b[39;49mexperiment_custom_tags,\n\u001b[0;32m    668\u001b[0m     log_plots\u001b[39m=\u001b[39;49mlog_plots,\n\u001b[0;32m    669\u001b[0m     log_profile\u001b[39m=\u001b[39;49mlog_profile,\n\u001b[0;32m    670\u001b[0m     log_data\u001b[39m=\u001b[39;49mlog_data,\n\u001b[0;32m    671\u001b[0m     silent\u001b[39m=\u001b[39;49msilent,\n\u001b[0;32m    672\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    673\u001b[0m     profile\u001b[39m=\u001b[39;49mprofile,\n\u001b[0;32m    674\u001b[0m     profile_kwargs\u001b[39m=\u001b[39;49mprofile_kwargs,\n\u001b[0;32m    675\u001b[0m )\n",
      "File \u001b[1;32me:\\anaconda\\lib\\site-packages\\pycaret\\internal\\tabular.py:268\u001b[0m, in \u001b[0;36msetup\u001b[1;34m(data, target, ml_usecase, available_plots, train_size, test_data, preprocess, imputation_type, iterative_imputation_iters, categorical_features, categorical_imputation, categorical_iterative_imputer, ordinal_features, high_cardinality_features, high_cardinality_method, numeric_features, numeric_imputation, numeric_iterative_imputer, date_features, ignore_features, normalize, normalize_method, transformation, transformation_method, handle_unknown_categorical, unknown_categorical_method, pca, pca_method, pca_components, ignore_low_variance, combine_rare_levels, rare_level_threshold, bin_numeric_features, remove_outliers, outliers_threshold, remove_multicollinearity, multicollinearity_threshold, remove_perfect_collinearity, create_clusters, cluster_iter, polynomial_features, polynomial_degree, trigonometry_features, polynomial_threshold, group_features, group_names, feature_selection, feature_selection_threshold, feature_selection_method, feature_interaction, feature_ratio, interaction_threshold, fix_imbalance, fix_imbalance_method, transform_target, transform_target_method, data_split_shuffle, data_split_stratify, fold_strategy, fold, fold_shuffle, fold_groups, n_jobs, use_gpu, custom_pipeline, html, session_id, log_experiment, experiment_name, experiment_custom_tags, log_plots, log_profile, log_data, silent, verbose, profile, profile_kwargs, display)\u001b[0m\n\u001b[0;32m    265\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msklearn==\u001b[39m\u001b[39m{\u001b[39;00m__version__\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    267\u001b[0m     \u001b[39mif\u001b[39;00m version\u001b[39m.\u001b[39mparse(__version__) \u001b[39m!=\u001b[39m version\u001b[39m.\u001b[39mparse(\u001b[39m\"\u001b[39m\u001b[39m0.23.2\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 268\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    269\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThis version of PyCaret requires scikit-learn==0.23.2, got \u001b[39m\u001b[39m{\u001b[39;00m__version__\u001b[39m}\u001b[39;00m\u001b[39m. Support for newer scikit-learn versions will be added in a future release.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    270\u001b[0m         )\n\u001b[0;32m    272\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[0;32m    273\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\u001b[39m\"\u001b[39m\u001b[39msklearn not found\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: This version of PyCaret requires scikit-learn==0.23.2, got 1.0.2. Support for newer scikit-learn versions will be added in a future release."
     ]
    }
   ],
   "source": [
    "from pycaret.classification import *\n",
    "clf1 = setup(data=data, target='Class')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7758e92e9a61d7a3490898707f7eeb937c85e9d1e8d4e877cc6c187218f226d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
